{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9481ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Float Numbers with Alphabet: 1.279M\n",
      "\f",
      "\n",
      "Extracted Float Numbers with Alphabet: ['76.78%']\n",
      "Extracted Float Numbers with Alphabet: 19.49M\n",
      "\f",
      "\n",
      "Extracted Float Numbers with Alphabet: ['70.52%']\n",
      "Extracted Float Numbers with Alphabet: 20.23M\n",
      "\f",
      "\n",
      "Extracted Float Numbers with Alphabet: ['65.94%']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5060/1858419577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Wait for the page to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Capture the highlighted area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import pytesseract\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import datetime\n",
    "\n",
    "\n",
    "domains=pd.read_excel(\"domain.xlsx\")\n",
    "domains=domains[\"domain\"]\n",
    "def extract_floats_with_alphabet(text):\n",
    "    # Perform text processing to extract floating-point numbers with exactly one alphabet and percentage sign\n",
    "    float_pattern = r'[-+]?\\d{1,3}(?:,\\d{3})*\\.\\d+%|\\d+\\.\\d+%|\\d{1,3}(?:,\\d{3})*\\.\\d+%|\\d+\\.\\d+%'\n",
    "    float_matches = re.findall(float_pattern, text)\n",
    "    return float_matches\n",
    "\n",
    "def capture_highlighted_area_total_visits(screenshot_path):\n",
    "    \n",
    "    # Get the screen dimensions\n",
    "    screen_width, screen_height = ImageGrab.grab().size\n",
    "    \n",
    "    # Define the region of interest (ROI) as per your requirement\n",
    "    roi_left = 440\n",
    "    roi_top = screen_height - 90  # Adjust as needed\n",
    "    roi_width = int(screen_width * 0.08)  # Adjust as needed\n",
    "    roi_height = 150  # Adjust as neededAdjust as needed\n",
    "    \n",
    "    # Capture the screenshot of the highlighted area\n",
    "    screenshot = ImageGrab.grab(bbox=(roi_left, roi_top, roi_left + roi_width, roi_top + roi_height))\n",
    "    \n",
    "    # Save the screenshot\n",
    "    screenshot.save(screenshot_path)\n",
    "    \n",
    "def capture_highlighted_area_device_configuration(screenshot_path):\n",
    "    \n",
    "    # Get the screen dimensions\n",
    "    screen_width, screen_height = ImageGrab.grab().size\n",
    "    \n",
    "    # Define the region of interest (ROI) as per your requirement\n",
    "    roi_left = 1100\n",
    "    roi_top = screen_height - 170  # Adjust as needed\n",
    "    roi_width = int(screen_width * 0.08)  # Adjust as needed\n",
    "    roi_height = 150  # Adjust as neededAdjust as needed\n",
    "    \n",
    "    # Capture the screenshot of the highlighted area\n",
    "    screenshot = ImageGrab.grab(bbox=(roi_left, roi_top, roi_left + roi_width, roi_top + roi_height))\n",
    "    \n",
    "    # Save the screenshot\n",
    "    screenshot.save(screenshot_path)\n",
    "\n",
    "data = []\n",
    "\n",
    "for domain in domains:\n",
    "    # Generate URL based on the domain\n",
    "    url = f\"https://pro.similarweb.com/#/digitalsuite/websiteanalysis/overview/website-performance/*/999/3m?webSource=Total&key={domain}\"\n",
    "    \n",
    "    # Open URL in browser\n",
    "    webbrowser.open_new_tab(url)\n",
    "    \n",
    "    # Wait for the page to load\n",
    "    time.sleep(35)\n",
    "\n",
    "    # Capture the highlighted area\n",
    "    screenshot_path_total_visits = \"highlighted_area_total_visits.png\"\n",
    "    screenshot_path_device_configuration = \"highlighted_area_device_configuration.png\"\n",
    "    capture_highlighted_area_total_visits(screenshot_path_total_visits)\n",
    "    capture_highlighted_area_device_configuration(screenshot_path_device_configuration)\n",
    "\n",
    "    # Load the screenshot image\n",
    "    screenshot_image_total_visits = Image.open(screenshot_path_total_visits)\n",
    "    screenshot_image_device_configuration = Image.open(screenshot_path_device_configuration)\n",
    "\n",
    "    # Apply OCR to the screenshot\n",
    "    extracted_text_total_visits = pytesseract.image_to_string(screenshot_image_total_visits)\n",
    "    extracted_text_device_configuration = pytesseract.image_to_string(screenshot_image_device_configuration)\n",
    "\n",
    "    # Extract floating-point numbers with alphabet suffix from the OCR output\n",
    "    float_numbers_with_alphabet_total_visits = (extracted_text_total_visits)\n",
    "    float_numbers_with_alphabet_device_configuration = extract_floats_with_alphabet(extracted_text_device_configuration)\n",
    "\n",
    "    # Print the extracted floating-point numbers with alphabet suffix\n",
    "    print(\"Extracted Float Numbers with Alphabet:\", float_numbers_with_alphabet_total_visits)\n",
    "    print(\"Extracted Float Numbers with Alphabet:\", float_numbers_with_alphabet_device_configuration)\n",
    "    \n",
    "    # Append the extracted data to the DataFrame\n",
    "    data.append({\n",
    "        'Domain': domain,\n",
    "        'Total Visits': float_numbers_with_alphabet_total_visits,\n",
    "        'Device Configuration': float_numbers_with_alphabet_device_configuration\n",
    "    })\n",
    "\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate a timestamp for the filename\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Save the DataFrame to a CSV file with a timestamp in the filename\n",
    "csv_filename = f'extracted_data_{timestamp}.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c31f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains=pd.read_excel(\"domain.xlsx\")\n",
    "domain=domains[\"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6164263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           123anime.info\n",
       "1               4anime.gg\n",
       "2        kissanime.com.ru\n",
       "3             9animetv.to\n",
       "4         dubbedanime.biz\n",
       "5        anime-planet.com\n",
       "6           aniwatchtv.to\n",
       "7          animeflix.live\n",
       "8     animefillerlist.com\n",
       "9              aniwave.to\n",
       "10           webtoons.com\n",
       "11                anix.vc\n",
       "12           animepahe.ru\n",
       "13          yugenanime.tv\n",
       "14            allmanga.to\n",
       "15          gogotaku.info\n",
       "16           mangadex.org\n",
       "Name: domain, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ebc82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
